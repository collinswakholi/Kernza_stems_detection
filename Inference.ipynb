{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di_VZUFGHFh3"
      },
      "source": [
        "# **1. Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIDbXGcIFu0S",
        "outputId": "0749d325-7e9b-4d52-8b5f-571f210d88fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udLiDvzbHO3G"
      },
      "source": [
        "# **2. Change Working directory, list file contents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px7Q3M0HF24D",
        "outputId": "2ae029e6-0355-4237-d31f-3dc5ec5c6cb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/Shareddrives/KernzaPhenoMethods/StemQuantification\n",
            "Documents      IlastikOutput  RawImages\t\t TrainingImages  YOLOOutput\n",
            "IlastikModels  kernza_stems   test_inference.py  YOLOModels\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#os.chdir(\"/content/drive/Shareddrives/KernzaPhenoMethods/StemQuantification\") # change this to the path of your project folder\n",
        "\n",
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib3BtfvRHbKW"
      },
      "source": [
        "# **3. Install Ultralytics, do checks, check for gpu**\n",
        "\n",
        "If an error message _\"NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\"_ is returned, Inference will done on CPU which is extremely **SLOW**.\n",
        "\n",
        "---\n",
        "Please check your colab runtime environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgLj5loiF5ea",
        "outputId": "3803544a-b0cc-4ecd-e61a-ce1b2d73f027"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.117 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.3/78.2 GB disk)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Jun 13 22:20:21 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv-4tF5pHnIO"
      },
      "source": [
        "# **4. Import dependencies, set parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWYczWCSF-kD",
        "outputId": "efce6c49-ee73-4fb4-b802-77e867e4fe1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NUmber of images found = 842\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import time\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "import cv2\n",
        "from readQR import ReadQR\n",
        "import readQR.wechat_artefacts as artefacts\n",
        "art_dir = artefacts.__path__[0]\n",
        "\n",
        "img_sz = 2048\n",
        "\n",
        "\n",
        "# set the inference parameters\n",
        "name = 'yolov8_model_'+str(img_sz)+'_1_test_salina' # set the name to give the results folder\n",
        "project = 'YOLO_results'\n",
        "save = True # save image results  ######################################################################\n",
        "save_txt = False # save results to *.txt\n",
        "save_conf = False # save confidences in --save-txt labels\n",
        "show_labels = False   # hide labels\n",
        "show_conf = False # hide confidences\n",
        "line_width = 2\n",
        "batch = -1 # batch size\n",
        "visualize = False # visualize model features\n",
        "conf_thres = 0.28 # confidence threshold\n",
        "iou_thres = 0.55 # NMS IoU threshold\n",
        "imgsz = img_sz # inference size (pixels)\n",
        "exist_ok = True # if True, it overwrites current 'name' saving folder #####################################\n",
        "half = True # use FP16 half-precision inference True/False\n",
        "cache = True # use cache images for faster inference\n",
        "\n",
        "img_fmt = '.JPG' # define the image format\n",
        "\n",
        "image_folder = \"Garett_Object_Detection/Test_salina\" # insert path to folder with images here\n",
        "base_folder = os.path.basename(image_folder)\n",
        "\n",
        "img_paths = glob.glob(os.path.join(image_folder, '**/*'+img_fmt), recursive=True) #get the path of each image in folder and subfolders\n",
        "# exclude file paths wit \"B_\"\n",
        "img_paths = [x for x in img_paths if \"B_\" not in x]\n",
        "\n",
        "# shuffle the list of images\n",
        "np.random.shuffle(img_paths)\n",
        "\n",
        "num_imgs = len(img_paths)\n",
        "print(\"NUmber of images found = \"+str(num_imgs))\n",
        "\n",
        "nx = 10 # number of images to process at a time\n",
        "img_paths2 = [img_paths[i:i + nx] for i in range(0, len(img_paths), nx)]\n",
        "\n",
        "# load the model\n",
        "model_location = 'Garett_Object_Detection/kernza_stems/yolov8_model_'+str(img_sz)+'_1/weights/best.pt' # change this to the location of your model\n",
        "model = YOLO(model_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXz_aoBdHvWH"
      },
      "source": [
        "# **5. Do Inference on the image folder, save the stem counts in a csv file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3ICi9duJ4US"
      },
      "outputs": [],
      "source": [
        "# initialize QR reader\n",
        "qr_reader = ReadQR(artefact_path=art_dir)\n",
        "show = None # None, 'single', 'continuous' # preview results 'single' or 'continuous' (video)\n",
        "\n",
        "for i, img_paths in enumerate(img_paths2):\n",
        "  save_name = 'stem_count_'+base_folder+'_'+str(i)+'.csv' # change name when you change folder\n",
        "\n",
        "  # read QR code if able\n",
        "  Qr_Names = []\n",
        "  for img_path in img_paths:\n",
        "    img = cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
        "    results = qr_reader.decode(img, show=show)\n",
        "    if len(results) == 0:\n",
        "      print('No QR code detected for \"'+img_path+'\"')\n",
        "      Qr_Names.append(\"QR code not detected!!!\")\n",
        "    else:\n",
        "      Qr_Names.append(results[0])\n",
        "  \n",
        "  # do inference and save\n",
        "  tic = time.time()\n",
        "  img_results = model.predict(source=img_paths, save=save, save_txt=save_txt, save_conf=save_conf, show_labels=show_labels, show_conf=show_conf,\n",
        "                              line_width=line_width, visualize=visualize, project=project, name=name, imgsz=imgsz, conf=conf_thres, half=half,\n",
        "                              iou=iou_thres, exist_ok=exist_ok, batch=batch, cache=cache\n",
        "  )\n",
        "\n",
        "  elapsed = 1000*(time.time()-tic)\n",
        "  time_per_image = elapsed/num_imgs\n",
        "  print(\"Infernce time per image = \"+str(time_per_image)+ \" ms\")\n",
        "\n",
        "  # loop through the results, get stem count, save\n",
        "  # Predictions = pd.DataFrame(columns = ['ImagePath','StemCount'])\n",
        "  Predictions = pd.DataFrame(columns = ['ImagePath','QRcodeInfo','StemCount'])\n",
        "  n = 0\n",
        "  for img_result in img_results:\n",
        "    # preds = img_result.__getitem__(0)\n",
        "    preds = img_result\n",
        "    try:\n",
        "      preds = preds.cpu().numpy()\n",
        "    except:\n",
        "      print('Prediction was on CPU')\n",
        "    \n",
        "    n_dets = int(len(preds))\n",
        "    im_name = img_paths[n]\n",
        "    qr_info = Qr_Names[n]\n",
        "\n",
        "    Predictions.at[n,'ImagePath'] = im_name\n",
        "    Predictions.at[n,'StemCount'] = n_dets\n",
        "    Predictions.at[n,'QRcodeInfo'] = qr_info\n",
        "    n+=1\n",
        "\n",
        "  # save results in csv\n",
        "  Predictions.to_csv(save_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
